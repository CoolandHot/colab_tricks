{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoolandHot/colab_tricks/blob/main/spark_cluster_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Tutorial on setting up Spark Cluster](https://medium.com/@jootorres_11979/how-to-install-and-set-up-an-apache-spark-cluster-on-hadoop-18-04-b4d70650ed42)"
      ],
      "metadata": {
        "id": "XK0mB-KzJOep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MASTER_IP = '172.28.0.2'\n",
        "Slave0_IP = '172.28.0.3'"
      ],
      "metadata": {
        "id": "rDJkdnR7NxgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prerequisites\n",
        "%%capture\n",
        "Path_of_JAVA_installation = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "Spark_folder = \"/usr/local/spark\"\n",
        "\n",
        "!pip install pyspark\n",
        "# findspark will locate Spark on the system and import it as a regular library.\n",
        "!pip install -q findspark\n",
        "\n",
        "# ping tool\n",
        "!apt-get install iputils-ping\n",
        "# SSH\n",
        "!apt-get install openssh-server openssh-client\n",
        "\n",
        "# Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Scala\n",
        "!apt-get install scala\n",
        "# Apache Spark with Hadoop\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!mv spark-3.2.0-bin-hadoop3.2 {Spark_folder}\n",
        "# Spark UI\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "\n",
        "# check hostname to vm0\n",
        "!hostname vm0\n",
        "with open('/etc/hosts', 'w') as file_object:\n",
        "    host_text = '''127.0.0.1\tlocalhost\n",
        " ::1\tlocalhost ip6-localhost ip6-loopback\n",
        " fe00::0\tip6-localnet\n",
        " ff00::0\tip6-mcastprefix\n",
        " ff02::1\tip6-allnodes\n",
        " ff02::2\tip6-allrouters\n",
        " ''' + f'{MASTER_IP}\tvm0\\n {Slave0_IP}\tvm1'\n",
        "    file_object.write(host_text)\n",
        "\n",
        "%cd /usr/local/spark/conf\n",
        "# copy the template to a .sh file\n",
        "!cp spark-env.sh.template spark-env.sh\n",
        "with open('spark-env.sh', 'a') as file_object:\n",
        "    file_object.write(f'\\nexport SPARK_MASTER_HOST=\"{MASTER_IP}\" export JAVA_HOME={Path_of_JAVA_installation}\\n')\n",
        "with open('slaves', 'a') as file_object:\n",
        "    file_object.write('\\nvm0\\n')\n",
        "    file_object.write('vm1\\n')\n",
        "\n",
        "%cd /content/\n",
        "with open('/root/.bashrc', 'a') as file_object:\n",
        "    file_object.write('\\nexport PATH = $PATH:/usr/local/spark/bin\\n')\n",
        "# sourcing the ~/.bashrc file\n",
        "!source ~/.bashrc\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = Path_of_JAVA_installation\n",
        "os.environ[\"SPARK_HOME\"] = Spark_folder\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3q9P4tIMwxdD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version\n",
        "!scala -version\n",
        "!ping vm1 -c 3\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "nfYdw5Vy9nVT",
        "outputId": "885bfc62-4d90-4097-fdbc-979d40481c17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.13\" 2021-10-19\n",
            "OpenJDK Runtime Environment (build 11.0.13+8-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.13+8-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "Scala code runner version 2.11.12 -- Copyright 2002-2017, LAMP/EPFL\n",
            "PING vm1 (172.28.0.3) 56(84) bytes of data.\n",
            "64 bytes from vm1 (172.28.0.3): icmp_seq=1 ttl=64 time=0.079 ms\n",
            "64 bytes from vm1 (172.28.0.3): icmp_seq=2 ttl=64 time=0.086 ms\n",
            "64 bytes from vm1 (172.28.0.3): icmp_seq=3 ttl=64 time=0.062 ms\n",
            "\n",
            "--- vm1 ping statistics ---\n",
            "3 packets transmitted, 3 received, 0% packet loss, time 2077ms\n",
            "rtt min/avg/max/mdev = 0.062/0.075/0.086/0.014 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/usr/local/lib/python3.7/dist-packages/pyspark'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.ssh/\n",
        "!ssh-keygen -t rsa -P \"\" -f ~/.ssh/id_rsa\n",
        "!cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZPUkdvb-MnC",
        "outputId": "73ca2c56-de90-4d55-f59a-18e67eb9fb20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Your identification has been saved in /root/.ssh/id_rsa.\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub.\n",
            "The key fingerprint is:\n",
            "SHA256:WY/qHArQwF4c8T6qJxBW0JYCkuk4n+/0+8BHYoBN1w0 root@vm0\n",
            "The key's randomart image is:\n",
            "+---[RSA 2048]----+\n",
            "|++o =...Eo       |\n",
            "|+o X +  . .      |\n",
            "|o B = .   .      |\n",
            "|++ + o   o o     |\n",
            "|.+o.. = S . .    |\n",
            "|. o. + + .       |\n",
            "| . .+ o +        |\n",
            "|  .ooo * .       |\n",
            "|  .+. +o+        |\n",
            "+----[SHA256]-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh-copy-id root@vm1"
      ],
      "metadata": {
        "id": "hhv3ceia-u6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# login the vm0\n",
        "!ssh vm1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ym2QlXjAyAa",
        "outputId": "f245feb5-0f8f-45cf-d54b-749ce0312e44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssh: Could not resolve hostname vm0: Name or service not known\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /usr/local/spark\n",
        "!sbin/start-master.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJG3IOVqB9qx",
        "outputId": "1b493d62-0eb3-4841-ebac-da7cb16371d8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/spark/conf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check to if the services started\n",
        "!jps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O58BbTMEEWF",
        "outputId": "e88748ac-7013-4123-b2ee-147060d051e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1298 Jps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YSjd5wDFMssg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "spark_cluster_setup",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}